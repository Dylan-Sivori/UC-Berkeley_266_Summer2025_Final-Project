{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"w123YU09-RvZ"},"outputs":[],"source":["!pip install -q -U transformers\n","!pip install -q -U datasets\n","!pip install -q -U evaluate\n","!pip install -q -U tokenizers\n","!pip install -q -U bitsandbytes\n","!pip install -q rouge_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3qgeM_E-kmL"},"outputs":[],"source":["import re\n","import random\n","import numpy as np\n","from scipy.special import softmax\n","import pprint\n","\n","import bitsandbytes as bnb\n","\n","import torch\n","import transformers\n","import evaluate\n","from datasets import Dataset, load_dataset, DatasetDict\n","\n","# For from-scratch T5 model\n","from transformers import T5TokenizerFast, T5Config, T5ForConditionalGeneration\n","\n","# For pre-trained T5 model\n","from transformers import T5Tokenizer, T5ForConditionalGeneration  # this won't import twice, just noting here what's for each model\n","\n","# For all T5 models\n","from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n","\n","# For BLEURT (to load a trained model for evaluation)\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","\n","# For style classifier model (also for evaluating the seq2seq model output)\n","from transformers import BertTokenizer, BertForSequenceClassification, BitsAndBytesConfig,pipeline\n","from transformers import TrainingArguments, Trainer\n","\n","import pandas as pd\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"b9X2R6w0VZy4"},"source":["# Local Data Loading Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ox05RdjWkQFW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752691384240,"user_tz":420,"elapsed":3003,"user":{"displayName":"Danielle Yoseloff","userId":"04768996262391462761"}},"outputId":"7ee3bfb3-b979-4126-9fc8-ecdeb1df3ef9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# This cell will authenticate you and mount your Drive in the Colab.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lM-KHBb4kRL5"},"outputs":[],"source":["# Path to data save in Drive\n","train = 'FairytaleQA_train.csv'\n","valid = 'FairytaleQA_valid.csv'\n","test = 'FairytaleQA_test.csv'\n","# path = 'drive/MyDrive/266_Danielle_Dylan_final_project/data/' #DYLAN\n","path = '/content/drive/MyDrive/266/FinalProject/data/' #DANIELLE personal\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bN5DFjg8mrfX"},"outputs":[],"source":["train = path+train\n","valid = path+valid\n","test = path+test\n","\n","train = pd.read_csv(train)\n","valid = pd.read_csv(valid)\n","test = pd.read_csv(test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u4z65l8eVZBf"},"outputs":[],"source":["train_ds = Dataset.from_pandas(train, split=\"train\")\n","test_ds = Dataset.from_pandas(test, split=\"test\")\n","valid_ds = Dataset.from_pandas(valid, split=\"test\")\n","\n","# Combine into a single DatasetDict\n","ds = DatasetDict({\n","    \"train\": train_ds,\n","    \"test\": test_ds,\n","    \"validation\": valid_ds,\n","})"]},{"cell_type":"markdown","metadata":{"id":"Byl4U6M6qlaK"},"source":["# Remote Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQVvpm_SVfjt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752691406494,"user_tz":420,"elapsed":48,"user":{"displayName":"Danielle Yoseloff","userId":"04768996262391462761"}},"outputId":"106dbb1e-896c-4227-fea6-298ef460cb36"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'answer1': 'kind and just .',\n"," 'answer2': None,\n"," 'attribute': 'character',\n"," 'ex_or_im': 'explicit',\n"," 'ex_or_im2': None,\n"," 'local_or_sum': 'local',\n"," 'question': 'what type of ruler was the king ?',\n"," 'story_name': 'three-dogs',\n"," 'story_section': 'once upon a time there was a king who went forth into the '\n","                  'world and fetched back a beautiful queen . and after they '\n","                  'had been married a while god gave them a little daughter . '\n","                  'then there was great rejoicing in the city and throughout '\n","                  'the country , for the people wished their king all that was '\n","                  'good , since he was kind and just . while the child lay in '\n","                  'its cradle , a strange - looking old woman entered the room '\n","                  ', and no one knew who she was nor whence she came . the old '\n","                  'woman spoke a verse over the child , and said that she must '\n","                  'not be allowed out under the open sky until she were full '\n","                  'fifteen years of age , since otherwise the mountain troll '\n","                  'would fetch her . when the king heard this he took her '\n","                  'words to heart , and posted guards to watch over the little '\n","                  'princess so that she would not get out under the open sky .'}\n"]}],"source":["pprint.pprint(ds['train'][1])"]},{"cell_type":"code","source":["# \"\"\"\n","# Initialize the pipeline with bitsandbytes quantization\n","# \"\"\"\n","# # Configure bitsandbytes for 4-bit quantization\n","# quantization_config = BitsAndBytesConfig(\n","#     load_in_4bit=True,\n","#     bnb_4bit_use_double_quant=True,\n","#     bnb_4bit_quant_type=\"nf4\",\n","#     bnb_4bit_compute_dtype=torch.bfloat16\n","# )\n","\n","# # Initialize pipeline\n","# model_id = \"google/flan-t5-small\""],"metadata":{"id":"84ei0D2Be9K_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# quantized_model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=\"cuda:0\", quantization_config=quantization_config)"],"metadata":{"id":"qS6xMta9e88l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0S5wpXenhjKR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lUbevKTus4_F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752691412766,"user_tz":420,"elapsed":1634,"user":{"displayName":"Danielle Yoseloff","userId":"04768996262391462761"}},"outputId":"2d36f440-fb50-49ae-d6d9-37b1c6cc7d46"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]}],"source":["\"\"\"\n","Initialize the pipeline with bitsandbytes quantization\n","\"\"\"\n","# Configure bitsandbytes for 4-bit quantization\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","# Initialize pipeline\n","model_id = \"google/flan-t5-small\"\n","\n","pipe = pipeline(\n","   \"text2text-generation\",\n","   model=model_id,\n","   model_kwargs={\"torch_dtype\": torch.bfloat16, \"quantization_config\": quantization_config},\n","   device_map=\"auto\",\n","   trust_remote_code=True\n",")\n","\n"]},{"cell_type":"code","source":["# quantized_model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=quantization_config)\n"],"metadata":{"id":"ivhi-6mF8hfg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n","\n","# model_8bit = AutoModelForCausalLM.from_pretrained(\n","#     \"bigscience/bloom-1b7\",\n","#     device_map=\"auto\",\n","#     quantization_config=quantization_config\n","# )"],"metadata":{"id":"q3cYfSes8upQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":781,"status":"ok","timestamp":1752361814987,"user":{"displayName":"Danielle Yoseloff","userId":"04768996262391462761"},"user_tz":420},"id":"NHcWsU_Ra7R5","outputId":"375e04cb-11a9-4925-d4a5-d9ccb4996883"},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]}],"source":["\n","# VOCAB_SIZE = 15000\n","\n","# MODEL_NAME= \"google/flan-t5-small\"\n","# tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n","\n","# # model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, quantization_config=quantization_config)\n","# # qa_model = pipeline(\"question-answering\",model=MODEL_NAME)\n","\n","# # data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=qa_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SAsMfKLXYoLW"},"outputs":[],"source":["train = ds['train'].shuffle()\n","val = ds['validation'].shuffle()\n","test = ds['test'].shuffle()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1752691421073,"user":{"displayName":"Danielle Yoseloff","userId":"04768996262391462761"},"user_tz":420},"id":"6iSQQcHu8C0V","outputId":"890b1928-df08-47f0-b124-13ef5e9dcae1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['story_name', 'story_section', 'question', 'answer1', 'answer2', 'local_or_sum', 'attribute', 'ex_or_im', 'ex_or_im2'],\n","    num_rows: 8548\n","})"]},"metadata":{},"execution_count":21}],"source":["train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pnk2YNrLdy41"},"outputs":[],"source":["# # We prefix our tasks with \"answer the question\"\n","# prefix = \"Please answer this question: \"\n","# context = \" Context: \"\n","\n","# # Define the preprocessing function\n","\n","# def preprocess_function(data):\n","#    \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n","#    # The \"inputs\" are the tokenized answer:\n","#    inputs = [prefix + question + context for question,context in zip(data[\"question\"],data['story_section'])]\n","#    model_inputs = tokenizer(text_target=inputs,\n","#                       max_length=512,\n","#                       truncation=True,\n","#                       padding='max_length',\n","#                             return_tensors='pt')\n","\n","#    # The \"labels\" are the tokenized outputs:\n","#    labels = tokenizer(text_target=data[\"answer1\"],\n","#                       max_length=512,\n","#                       truncation=True,\n","#                       padding='max_length',\n","#                       return_tensors='pt')\n","\n","#    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","#    return model_inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MI2AJqo-evIm"},"outputs":[],"source":["# # Map the preprocessing function across our dataset\n","# train_tokenized = train.map(preprocess_function, batched=True)\n","# val_tokenized = val.map(preprocess_function, batched=True)\n","# test_tokenized = test.map(preprocess_function, batched=True)\n","\n","# train_tokenzied = {'input_ids': train_tokenized['input_ids'], 'labels': train_tokenized['labels']}\n","# val_tokenzied = {'input_ids': val_tokenized['input_ids'], 'labels': val_tokenized['labels']}\n","# test_tokenzied = {'input_ids': test_tokenized['input_ids'], 'labels': test_tokenized['labels']}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HOYkFY_BqlLI"},"outputs":[],"source":["# len(train_tokenzied['input_ids'][400])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ynVXKRO1e2Z9"},"outputs":[],"source":["# def create_seq2seq_training_args(batch_size, num_epochs):\n","\n","#     training_args = Seq2SeqTrainingArguments(\n","#         \"fairytale_QA_model\",\n","#         eval_strategy='epoch',\n","#         per_device_train_batch_size=batch_size,\n","#         per_device_eval_batch_size=batch_size,\n","#         num_train_epochs=num_epochs,\n","#         report_to='none'\n","\n","#     )\n","\n","#     return training_args"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6WOtKKx5gwrI"},"outputs":[],"source":["# def create_seq2seq_trainer(model, training_args, train_ds, val_ds):\n","\n","#     trainer = Seq2SeqTrainer(\n","#         model,\n","#         training_args,\n","#         train_dataset=train_ds,\n","#         eval_dataset=val_ds\n","#     )\n","\n","#     return trainer"]},{"cell_type":"markdown","metadata":{"id":"RYypsX9f2icV"},"source":["# Fine Tuning (DNU)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awUAGO8xg6j0"},"outputs":[],"source":["# batch_size = 32\n","# num_epochs = 4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hm6GhsVwg-5w"},"outputs":[],"source":["# embed_dim = 300\n","# keyvalue_dim = 36\n","# num_heads = 6\n","# dense_dim = 850\n","# num_layers = 6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N_qseXyEiPM4"},"outputs":[],"source":["# training_args = create_seq2seq_training_args(batch_size, num_epochs)\n","# trainer = create_seq2seq_trainer(model,training_args,train_tokenized,val_tokenized)\n","\n","# trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"KdWd7bAl2nqt"},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l9hrxZSCktox","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["592970b89c754401a1bf87e5767f0ac0","aa191a7c60544bb7a8d84b65e4e29418","b81c6385ee70458c86f82fd75ef2f409","4b80026f792e4bfeadd3a856c2c32c0d","e542e682aeaa4ffe8be9b0d8dfc6efc5","f74af8e602124809a5c148dc95d84f0a","186b242721bb4842947d9867ccb65b06","e026ea4b6ef545d9ac875dc04f41ee21","a1dbf20e6b614219a5595e324efb888d","1692fae474f24264acbd460a69fbe1d8","b2739f721b6f4973baf56f3654089dd2"]},"executionInfo":{"status":"ok","timestamp":1752691429843,"user_tz":420,"elapsed":2257,"user":{"displayName":"Danielle Yoseloff","userId":"04768996262391462761"}},"outputId":"584455d6-f9af-4818-dcce-728f85ab0273"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"592970b89c754401a1bf87e5767f0ac0"}},"metadata":{}}],"source":["rouge = evaluate.load('rouge')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0mP1cAiZVrhN","colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"status":"ok","timestamp":1752691435083,"user_tz":420,"elapsed":3438,"user":{"displayName":"Danielle Yoseloff","userId":"04768996262391462761"}},"outputId":"b3e463e6-12b9-4563-cadb-89cc66fd636f"},"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/63 [00:03<?, ?it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \"\"\"\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         if (\n\u001b[1;32m    189\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m                 )\n\u001b[0;32m-> 1445\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1369\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generation_config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2642\u001b[0m             )\n\u001b[1;32m   2643\u001b[0m             \u001b[0;31m# 12. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2644\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2645\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   4077\u001b[0m             \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"output_hidden_states\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_hidden_states\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4079\u001b[0;31m             \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4081\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1793\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1106\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;31m# Apply Feed Forward layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;31m# clamp inf values to enable fp16 training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mhidden_gelu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwi_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0mhidden_linear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwi_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_gelu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhidden_linear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul_4bit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py\u001b[0m in \u001b[0;36mmatmul_4bit\u001b[0;34m(A, B, quant_state, out, bias)\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mMatMul4Bit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, A, B, out, bias, quant_state)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# 1. Dequantize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# 2. MatmulnN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdequantize_4bit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# 3. Save state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["%%time\n","\n","results = []\n","batch_size = 16\n","r = []\n","\n","for idx in tqdm(range(0,len(test),batch_size)):\n","  # if idx >= 50:  # Stop after processing 10 samples\n","  #   break\n","\n","  prefix = \"Please answer this question: \"\n","  context = \" Context: \"\n","\n","  batch = train[idx:idx+batch_size]\n","\n","  # for j in range(len(batch)):\n","  #   batch[j]['question'] = prefix + batch[j]['question'] + context + batch[j]['story_section']\n","\n","  # print(batch)\n","\n","  questions = []\n","  for j in range(0,len(batch['question'])):\n","    # print(batch)\n","    # print(batch['question'][j])\n","    q = prefix + batch['question'][j] + context + batch['story_section'][j]\n","    questions.append(q)\n","\n","\n","  # questions = [prefix + sample['question'] + context + sample['story_section'] for sample in batch]\n","\n","  # print('AAA',questions)\n","  # print(\"\\n\", len(questions))\n","\n","  # Generate summary via the pipeline\n","  outputs = pipe(\n","                      questions,\n","                      max_new_tokens=700,\n","  )\n","  # print(\"A\",outputs)\n","  # print(\"A2\",len(outputs))\n","\n","\n","  answer = outputs[0][\"generated_text\"]\n","  # print(\"B\",answer)\n","\n","  r.append(answer)\n","\n","\n","  # # Calculate ROUGE scores\n","\n","\n","\n","  # for sample in batch:\n","  #   print(\"C\",sample)\n","  #   predictions = [answer]\n","  #   print(\"D\",predictions)\n","  #   references = [[sample['answer1']]]\n","  #   print(\"E\",references)\n","  #   rouge_scores = rouge.compute(predictions=predictions, references=references)\n","  #   print(\"F\",rouge_scores)\n","\n","\n","  #   # Store results\n","  #   results.append({\n","  #       'id': idx,\n","  #       'ex_or_im': sample['ex_or_im'],\n","  #       'story_section': sample['story_section'][:500],  # Store truncated text for readability\n","  #       'reference_answer': sample['answer1'],\n","  #       'generated_answer': answer,\n","  #       **rouge_scores\n","  #   })\n","\n","  # Print progress update every 10 samples\n","  if (idx + 1) % 500 == 0:\n","      print(f\"\\nProcessed {idx + 1} samples\")\n","      # print(f\"Latest ROUGE-1: {rouge_scores['rouge1']:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46951,"status":"ok","timestamp":1752519647826,"user":{"displayName":"Danielle Yoseloff","userId":"04768996262391462761"},"user_tz":420},"id":"avaozm3QTT2o","outputId":"0eaa9ed4-9eaa-4e6b-ba75-b81b39c41934"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 10/8548 [00:09<1:53:45,  1.25it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  0%|          | 25/8548 [00:21<1:36:10,  1.48it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n","  1%|          | 50/8548 [00:46<2:12:46,  1.07it/s]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 42.6 s, sys: 542 ms, total: 43.2 s\n","Wall time: 46.9 s\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# %%time\n","\n","# results = []\n","\n","# for idx, sample in enumerate(tqdm(test)):\n","#   # if idx >= 50:  # Stop after processing 10 samples\n","#   #   break\n","#   prefix = \"Please answer this question: \"\n","#   context = \" Context: \"\n","\n","#   question = prefix + sample['question'] + context + sample['story_section']\n","#   # Generate summary via the pipeline\n","#   outputs = pipe(\n","#                       question,\n","#                       max_new_tokens=700,\n","#   )\n","\n","\n","#   answer = outputs[0][\"generated_text\"]\n","\n","\n","#   # Calculate ROUGE scores\n","#   predictions = [answer]\n","#   references = [[sample['answer1']]]\n","#   rouge_scores = rouge.compute(predictions=predictions, references=references)\n","\n","\n","#   # Store results\n","#   results.append({\n","#       'id': idx,\n","#       'ex_or_im': sample['ex_or_im'],\n","#       'story_section': sample['story_section'][:500],  # Store truncated text for readability\n","#       'reference_answer': sample['answer1'],\n","#       'generated_answer': answer,\n","#       **rouge_scores\n","#   })\n","\n","#   # Print progress update every 10 samples\n","#   if (idx + 1) % 500 == 0:\n","#       print(f\"\\nProcessed {idx + 1} samples\")\n","#       print(f\"Latest ROUGE-1: {rouge_scores['rouge1']:.4f}\")"]},{"cell_type":"code","source":["# def preprocess_function(data):\n","#    \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n","#    # The \"inputs\" are the tokenized answer:\n","#    inputs = [prefix + question + context for question,context in zip(data[\"question\"],data['story_section'])]\n","#    model_inputs = tokenizer(text_target=inputs,\n","#                       max_length=512,\n","#                       truncation=True,\n","#                       padding='max_length',\n","#                             return_tensors='pt')\n","\n","#    # The \"labels\" are the tokenized outputs:\n","#    labels = tokenizer(text_target=data[\"answer1\"],\n","#                       max_length=512,\n","#                       truncation=True,\n","#                       padding='max_length',\n","#                       return_tensors='pt')\n","\n","#    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","#    return model_inputs"],"metadata":{"id":"KFNZRnzcpv0p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["SIMILAR TO ORIGINAL"],"metadata":{"id":"MJLFLtLkTVKf"}},{"cell_type":"code","source":[],"metadata":{"id":"D5Hxq5aWl116"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %%time\n","\n","# # Store results for aggregate scoring\n","# results = []\n","# def process_dataset(dataset):\n","#   for idx, sample in enumerate(tqdm(dataset)):\n","\n","#       prefix = \"Please answer this question: \"\n","#       context = \" Context: \"\n","\n","#       question = prefix + sample['question'] + context + sample['story_section']\n","\n","#       # Generate summary via the pipeline\n","#       outputs = pipe(\n","#                           question,\n","#                           max_new_tokens=700,\n","#       )\n","\n","\n","#       answer = outputs[0][\"generated_text\"]\n","\n","\n","#       # Calculate ROUGE scores\n","#       predictions = [answer]\n","#       references = [[sample['answer1']]]\n","#       rouge_scores = rouge.compute(predictions=predictions, references=references)\n","\n","\n","#       # Store results\n","#       results.append({\n","#           'id': idx,\n","#           'ex_or_im': sample['ex_or_im'],\n","#           'story_section': sample['story_section'][:500],  # Store truncated text for readability\n","#           'reference_answer': sample['answer1'],\n","#           'generated_answer': answer,\n","#           **rouge_scores\n","#       })\n","\n","#       # Print progress update every 10 samples\n","#       if (idx + 1) % 500 == 0:\n","#           print(f\"\\nProcessed {idx + 1} samples\")\n","#           print(f\"Latest ROUGE-1: {rouge_scores['rouge1']:.4f}\")\n","\n","\n","#       if dataset == train:\n","#         filesuffix = \"train\"\n","#       elif dataset == valid:\n","#         filesuffix = \"val\"\n","#       elif dataset == test:\n","#         filesuffix = \"test\"\n","#       else:\n","#         filesuffix = \"\"\n","#       # Convert results to DataFrame\n","#       results_df = pd.DataFrame(results)\n","\n","#       # Save results in Drive, will overwrite existing file\n","#       # results_path = 'drive/MyDrive/266_Danielle_Dylan_final_project/results/'  #DYLAN\n","#       results_path = 'drive/MyDrive/266/FinalProject/results/'  #DANIELLE\n","#       results_df.to_csv(results_path+f'T5baseline_resultsdf_{filesuffix}.csv', index=False)\n","\n","#       return results_df\n"],"metadata":{"id":"uLgmvUiapfSh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752692449591,"user_tz":420,"elapsed":48,"user":{"displayName":"Danielle Yoseloff","userId":"04768996262391462761"}},"outputId":"133f6593-0e1c-45da-b82b-8c31e407c0c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 4 s, sys: 0 ns, total: 4 s\n","Wall time: 6.91 s\n"]}]},{"cell_type":"code","source":["# %%time\n","# test_results_df = process_dataset(test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"ku5VMDPVD_PK","executionInfo":{"status":"ok","timestamp":1752692453305,"user_tz":420,"elapsed":1007,"user":{"displayName":"Danielle Yoseloff","userId":"04768996262391462761"}},"outputId":"d7d40878-b83c-4b6c-edd1-7ee744f333ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/1007 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"ValueError","evalue":"Unable to coerce to Series, length must be 9: given 1007","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mprocess_dataset\u001b[0;34m(dataset)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7895\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# only relevant for Series other case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7897\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_align_for_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7899\u001b[0m         \u001b[0;31m# See GH#4537 for discussion of scalar op behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_align_for_op\u001b[0;34m(self, other, axis, flex, level)\u001b[0m\n\u001b[1;32m   8185\u001b[0m                 )\n\u001b[1;32m   8186\u001b[0m             \u001b[0;31m# GH#17901\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8187\u001b[0;31m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mflex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_series\u001b[0;34m(right)\u001b[0m\n\u001b[1;32m   8131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8133\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   8134\u001b[0m                         \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgiven_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8135\u001b[0m                     )\n","\u001b[0;31mValueError\u001b[0m: Unable to coerce to Series, length must be 9: given 1007"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1752693180758,"user":{"displayName":"Danielle Yoseloff","userId":"04768996262391462761"},"user_tz":420},"id":"Hc8Az-OP2mHY","outputId":"757f60d3-2601-4326-d14c-13fc56444d9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 4 s, sys: 0 ns, total: 4 s\n","Wall time: 7.39 s\n"]}],"source":["%%time\n","######ORIGINAL\n","\n","# Store results for aggregate scoring\n","results = []\n","def process_dataset(dataset):\n","  for idx, sample in enumerate(tqdm(dataset)):\n","      # if idx >= 50:  # Stop after processing 10 samples\n","      #   break\n","\n","      prefix = \"Please answer this question: \"\n","      context = \" Context: \"\n","\n","      question = prefix + sample['question'] + context + sample['story_section']\n","      # Generate summary via the pipeline\n","      outputs = pipe(\n","                          question,\n","                          max_new_tokens=700,\n","      )\n","\n","\n","      answer = outputs[0][\"generated_text\"]\n","\n","\n","      # Calculate ROUGE scores\n","      predictions = [answer]\n","      references = [[sample['answer1']]]\n","      rouge_scores = rouge.compute(predictions=predictions, references=references)\n","\n","\n","      # Store results\n","      results.append({\n","          'id': idx,\n","          'ex_or_im': sample['ex_or_im'],\n","          'story_section': sample['story_section'][:500],  # Store truncated text for readability\n","          'reference_answer': sample['answer1'],\n","          'generated_answer': answer,\n","          **rouge_scores\n","      })\n","\n","      # Print progress update every 10 samples\n","      if (idx + 1) % 500 == 0:\n","          print(f\"\\nProcessed {idx + 1} samples\")\n","          print(f\"Latest ROUGE-1: {rouge_scores['rouge1']:.4f}\")\n","\n","\n","          # if dataset == train:\n","          #   filesuffix = \"train\"\n","          # elif dataset == valid:\n","          #   filesuffix = \"val\"\n","          # elif dataset == test:\n","          #   filesuffix = \"test\"\n","          # else:\n","          #   filesuffix = \"\"\n","          # Convert results to DataFrame\n","          results_df = pd.DataFrame(results)\n","\n","          # # Save results in Drive, will overwrite existing file\n","          # # results_path = 'drive/MyDrive/266_Danielle_Dylan_final_project/results/'  #DYLAN\n","          # results_path = 'drive/MyDrive/266/FinalProject/results/'  #DANIELLE\n","          # results_df.to_csv(results_path+f'T5baseline_resultsdf_{filesuffix}.csv', index=False)\n","\n","          return results_df\n","\n","      # except Exception as e:\n","      #   print(f\"Error processing sample {idx}: {str(e)}\")\n","      #   continue\n","\n","# process_dataset(train)\n","# process_dataset(valid)\n","# process_dataset(test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5LsbdrWF_jf","outputId":"4ef18156-5e10-4c85-99af-cc957b1a42b8","executionInfo":{"status":"ok","timestamp":1752693665305,"user_tz":420,"elapsed":481273,"user":{"displayName":"Danielle Yoseloff","userId":"04768996262391462761"}}},"outputs":[{"output_type":"stream","name":"stderr","text":[" 50%|     | 499/1007 [08:01<08:09,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Processed 500 samples\n","Latest ROUGE-1: 0.7143\n","CPU times: user 7min 54s, sys: 2.83 s, total: 7min 56s\n","Wall time: 8min 1s\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["%%time\n","test_results_df = process_dataset(test)\n"]},{"cell_type":"code","source":["results_path = 'drive/MyDrive/266/FinalProject/results/'  #DANIELLE\n","test_results_df.to_csv(results_path+f'T5baseline_resultsdf_test.csv', index=False)"],"metadata":{"id":"QTQxl3nepu1S"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L3aNUngeMrqX"},"outputs":[],"source":["%%time\n","process_dataset(valid)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AYjJC3yxMvUZ"},"outputs":[],"source":["%%time\n","process_dataset(train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1752549603012,"user":{"displayName":"Danielle Yoseloff","userId":"04768996262391462761"},"user_tz":420},"id":"SB0VJKI4GGgG","outputId":"22e7f960-6286-4b71-d7d9-5ac42a03cd1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["1007 8548 1025\n"]}],"source":["print(len(test), len(train), len(valid))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qEsa2kiUIcP1"},"outputs":[],"source":["# Convert results to DataFrame\n","results_df = pd.DataFrame(results)\n","\n","# Save results in Drive, will overwrite existing file\n","# results_path = 'drive/MyDrive/266_Danielle_Dylan_final_project/results/'  #DYLAN\n","results_path = 'drive/MyDrive/266/FinalProject/results/'  #DANIELLE\n","results_df.to_csv(results_path+'T5baseline_resultsdf.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KoIoQvLfQvy2"},"outputs":[],"source":["results[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JY3-IVMomt3b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1752367608991,"user":{"displayName":"Danielle Yoseloff","userId":"04768996262391462761"},"user_tz":420},"id":"Pp-MqVI-7xXv","outputId":"e0f30cac-6111-4e8a-8c6f-fac9055c1830"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Average ROUGE Scores:\n","rouge1: 0.3265\n","rouge2: 0.1798\n","rougeL: 0.3191\n","\n","Average ROUGE Scores by Question type:\n","            rouge1    rouge2    rougeL\n","ex_or_im                              \n","explicit  0.401419  0.239823  0.394258\n","implicit  0.113302  0.009050  0.105205\n","\n","Example Summaries:\n","\n","Example 0:\n","Reference: angry .\n","Generated: dreadful\n","\n","Example 1:\n","Reference: happy .\n","Generated: glad\n","\n","Example 2:\n","Reference: seized the squirrel and ate him up .\n","Generated: ate him up\n","\n","Example 3:\n","Reference: trick the giant .\n","Generated: crushed it into fine sand\n","\n","Example 4:\n","Reference: he looked handsomer than ever for he was glided all over .\n","Generated: he was gilded all over .\n","\n","Example 5:\n","Reference: the great spirit .\n","Generated: the raspberry king\n","\n","Example 6:\n","Reference: an envious wizened .\n","Generated: an envious wizened basthard of a fellow\n","\n","Example 7:\n","Reference: seized the skin in their beaks and they flew quickly away .\n","Generated: the gulls flew straight as an arrow\n","\n","Example 8:\n","Reference: to enrish and season and flavour it .\n","Generated: it was a good meal .\n","\n","Example 9:\n","Reference: salmon .\n","Generated: elk\n","\n","Example 10:\n","Reference: this daughter had three eyes , for she had an eye in the back of her head .\n","Generated: she had an eye in the back of her head\n","\n","Example 11:\n","Reference: his skin became drawn and hardened .\n","Generated: the hare cried aloud\n","\n","Example 12:\n","Reference: they laid themselves down to the long slumber .\n","Generated: they all reappeared in the lodge\n","\n","Example 13:\n","Reference: she at once began to plan how she might marry the king .\n","Generated: drew the young princess to her\n","\n","Example 14:\n","Reference: it was made into paper .\n","Generated: they fell into rags and tatters and thought it was all over with them .\n","\n","Example 15:\n","Reference: satisfied .\n","Generated: kintaro did n't like the monkey .\n","\n","Example 16:\n","Reference: sad .\n","Generated: disappointed\n","\n","Example 17:\n","Reference: she did not want to lose her third child .\n","Generated: she was n't the nearer to keep the child to herself\n","\n","Example 18:\n","Reference: delighted .\n","Generated: she was very happy\n","\n","Example 19:\n","Reference: sad .\n","Generated: sad and wept many bitter tears\n","\n","Example 20:\n","Reference: buying or selling .\n","Generated: he rode across the hill and past the cottage of miguel the vine - keeper\n","\n","Example 21:\n","Reference: his great strength .\n","Generated: kintaro grew stronger and stronger .\n","\n","Example 22:\n","Reference: they found a raspberry wood .\n","Generated: They were able to pick a lot of raspberries .\n","\n","Example 23:\n","Reference: there was not a soul aboard .\n","Generated: they did n't want to overhear them .\n","\n","Example 24:\n","Reference: happy .\n","Generated: the sultana\n","\n","Example 25:\n","Reference: he could not keep up much longer .\n","Generated: the wife complained that her husband had grown so old and decrepit that he could not keep up much longer\n","\n","Example 26:\n","Reference: decorated her room .\n","Generated: she decorated her room .\n","\n","Example 27:\n","Reference: a little blue field flower .\n","Generated: a milestone\n","\n","Example 28:\n","Reference: a tree .\n","Generated: a tree\n","\n","Example 29:\n","Reference: go ashore and look around .\n","Generated: go ashore\n","\n","Example 30:\n","Reference: she will vanish completely .\n","Generated: the poor man will be relieved\n","\n","Example 31:\n","Reference: set about serving the evening meal and making everything as comfortable as she could .\n","Generated: set about serving the evening meal and making everything as comfortable as she could for him\n","\n","Example 32:\n","Reference: cried .\n","Generated: she ran to his side , and caught hold of his long sleeve to keep him a moment\n","\n","Example 33:\n","Reference: cross .\n","Generated: ah\n","\n","Example 34:\n","Reference: as much as he could carry .\n","Generated: the king 's son asked for a whole ton\n","\n","Example 35:\n","Reference: terrified .\n","Generated: None of the above choices\n","\n","Example 36:\n","Reference: he was trying to get jose out of his path .\n","Generated: the king did not want the king to send him in search of her .\n","\n","Example 37:\n","Reference: white hawks .\n","Generated: a white hawk\n","\n","Example 38:\n","Reference: the roots of the tree were enormous .\n","Generated: the roots of the tree were so enormous that one of the best springs in stommen flows from one of the root - holes to this very day .\n","\n","Example 39:\n","Reference: frightened .\n","Generated: frightened\n","\n","Example 40:\n","Reference: he might obtain the water of perpetual life .\n","Generated: None of the above choices .\n","\n","Example 41:\n","Reference: \" no one but yourself must pass on this side of the lodge . \" .\n","Generated: no one but yourself must pass on this side of the lodge\n","\n","Example 42:\n","Reference: content .\n","Generated: the peasant went his way , well content with his bargain .\n","\n","Example 43:\n","Reference: the royal castle .\n","Generated: the royal castle\n","\n","Example 44:\n","Reference: a troll has enchanted them .\n","Generated: the trolls have enchanted them .\n","\n","Example 45:\n","Reference: a tom - tit .\n","Generated: tom - tit\n","\n","Example 46:\n","Reference: happy .\n","Generated: happy\n","\n","Example 47:\n","Reference: a beautiful boy with three heads on him .\n","Generated: tom\n","\n","Example 48:\n","Reference: free the maidens .\n","Generated: dance in the field\n","\n","Example 49:\n","Reference: the woman did not have a bed for him .\n","Generated: halvor had to take a nap\n"]}],"source":["# Calculate and print average ROUGE scores\n","avg_scores = results_df[['rouge1', 'rouge2', 'rougeL']].mean()\n","print(\"\\nAverage ROUGE Scores:\")\n","for metric, score in avg_scores.items():\n","   print(f\"{metric}: {score:.4f}\")\n","\n","# Calculate average by question type\n","avg_by_type = results_df.groupby(['ex_or_im'])[['rouge1', 'rouge2', 'rougeL']].mean()\n","# for i in t.itertuples():\n","#   print(f\"\\nAverage {i.Index} ROUGE scores:\")\n","#   for metric, score in zip(metrics, i[1:]):\n","#     print(f\"{metric}: {score:.4f}\")\n","print(\"\\nAverage ROUGE Scores by Question type:\")\n","print(avg_by_type)\n","\n","# Print some example summaries\n","print(\"\\nExample Summaries:\")\n","for i in range(min(20, len(results_df))):\n","   print(f\"\\nExample {i}:\")\n","   print(f\"Reference: {results_df.iloc[i]['reference_answer']}\")\n","   print(f\"Generated: {results_df.iloc[i]['generated_answer']}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAgd2711-2cZ"},"outputs":[],"source":["train[48]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9n4xNoyyBpQ0"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["RYypsX9f2icV"],"gpuType":"T4","provenance":[{"file_id":"1K684XGAkc4dBOCcKENxBg3nL6rFe4_hi","timestamp":1752516563141},{"file_id":"10MPbM-9irkOT4DOXtjQhL1F0WsdFybDf","timestamp":1752357157682}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"592970b89c754401a1bf87e5767f0ac0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa191a7c60544bb7a8d84b65e4e29418","IPY_MODEL_b81c6385ee70458c86f82fd75ef2f409","IPY_MODEL_4b80026f792e4bfeadd3a856c2c32c0d"],"layout":"IPY_MODEL_e542e682aeaa4ffe8be9b0d8dfc6efc5"}},"aa191a7c60544bb7a8d84b65e4e29418":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f74af8e602124809a5c148dc95d84f0a","placeholder":"","style":"IPY_MODEL_186b242721bb4842947d9867ccb65b06","value":"Downloadingbuilderscript:"}},"b81c6385ee70458c86f82fd75ef2f409":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e026ea4b6ef545d9ac875dc04f41ee21","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a1dbf20e6b614219a5595e324efb888d","value":1}},"4b80026f792e4bfeadd3a856c2c32c0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1692fae474f24264acbd460a69fbe1d8","placeholder":"","style":"IPY_MODEL_b2739f721b6f4973baf56f3654089dd2","value":"6.27k/?[00:00&lt;00:00,554kB/s]"}},"e542e682aeaa4ffe8be9b0d8dfc6efc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f74af8e602124809a5c148dc95d84f0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"186b242721bb4842947d9867ccb65b06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e026ea4b6ef545d9ac875dc04f41ee21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a1dbf20e6b614219a5595e324efb888d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1692fae474f24264acbd460a69fbe1d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2739f721b6f4973baf56f3654089dd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}