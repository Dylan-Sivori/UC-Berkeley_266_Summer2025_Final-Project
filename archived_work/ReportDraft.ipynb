{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#266 Project Report Draft\n","\n","DATASCI 266 - Natural Language Processing - Summer 2025\n","\n","|Team Member|Email| Section |\n","|-|-|-|\n","|Dylan Sivori|dylan.sivori@berkeley.edu|004 Jennifer Zhu|\n","|Danielle Yoseloff|dyoseloff@berkeley.edu|002 Natalie Ahn|\n","\n","[Project Proposal Google Dococument](https://docs.google.com/document/d/1nAeU2EA507JKplb2-lUFSYJS2WYlgUIbj_XV7hK-AZw/edit?usp=sharing)\n"],"metadata":{"id":"-EViLKQ5WrZB"}},{"cell_type":"markdown","source":["A place for us to take notes about our decisions and experiments. Anything goes."],"metadata":{"id":"KgAGse_RWrWT"}},{"cell_type":"markdown","source":["* Why did we chooose FLAN-T5 small? We choose T5 as our baseline because it is a generative model set up to answer questions with context without any finetuning. We choose FLAN small because .....?\n","\n","* Why did we split the data the way we did? That's the way the dataset was already split. We assume there is a good distribution of question types across train/test/val"],"metadata":{"id":"LBwcqOCYWrTU"}},{"cell_type":"markdown","source":["# Guiding Research Question\n","- \"Will smaller specialized models (fine-tune on only implicit question types vs fine-tuned on only explicit question types) perform better on different question types rather than a singular model that handles both?\"\n","\n","# Experiments in 266_Danielle_Dylan_T5_SpecializedFineTuning.ipynb = \"resolving bugs\"\n","- Fine tuning FlanT5 on entire dataset (both explicit & implicit)\n","  - Use this fine-tuned model to then report on performance by implicit & explicit (DS to add overall performance)\n","- Fine tuning FlanT5 on explicit only dataset, then reporting on performance on only explicit only\n","- Fine tuning FlanT5 on implicit only dataset, then reporting on performance on only implicit only\n","- Then switched gears to try to improve implicit. Attempted CoT prompting\n","  - Did not see much success\n","- Tried fine tuning Llama on implicit only (but was too big), so instead tried QWEN (decoder only architecture)\n","\n","# Next Steps\n","- Seeing what professors think about hadnling multiple answer candidates\n","- Specialized model fine tuning experiments through 7/23\n","- Model aggregation/creation of pseudo-MoE from 7/24-7/27\n","- Final Week mayhem/paper writing/presentation creation 7/28-8/3"],"metadata":{"id":"VvGCCPwEWrQP"}},{"cell_type":"markdown","source":[],"metadata":{"id":"2UIc2faKWrNO"}}]}